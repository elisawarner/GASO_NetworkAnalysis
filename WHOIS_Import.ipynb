{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WhoIS Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You only get 500 credits with https://api.ip2whois.com/v2. But you can register another email address to continue on if you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiKey = apiKeyWHOIS\n",
    "url = \"https://api.ip2whois.com/v2\"\n",
    "querystring = {\"key\":apiKey,\"format\":\"json\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripName(nameStr):\n",
    "    pattern = \"(?<=://).*\"\n",
    "    try:\n",
    "        newName = re.findall(pattern, nameStr)[0]\n",
    "    except:\n",
    "        newName = nameStr\n",
    "    \n",
    "    if newName[-1] == '/':\n",
    "        return newName[:-1]\n",
    "    else:\n",
    "        return newName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawlJSON(JSONdict):\n",
    "    entryDict = {}\n",
    "    \n",
    "    level1header = list(JSONdict)\n",
    "    if \"error\" in level1header:\n",
    "        return {}\n",
    "    \n",
    "    for name in level1header:\n",
    "        if type(JSONdict[name]) == type({}):\n",
    "            level2names = list(JSONdict[name])        \n",
    "        \n",
    "            for name2 in level2names:\n",
    "                entryDict[name + \" \" + name2] = JSONdict[name][name2]\n",
    "        else:\n",
    "            entryDict[name] = JSONdict[name]\n",
    "\n",
    "    return entryDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(527, 2)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ScamWebsites file\n",
    "scamsites = pd.read_csv('ScamWebsites.csv')\n",
    "scamsites = scamsites[scamsites[\"API response\"] != 200]\n",
    "scamsites = scamsites[[\"Requested domain\", \"Domain name\"]]\n",
    "scamsites.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_idx in range(scamsites.shape[0]):\n",
    "    row = scamsites.iloc[row_idx]\n",
    "    if row[\"Domain name\"] != row[\"Domain name\"]: # nan\n",
    "        scamsites.iloc[row_idx][\"Domain name\"] = stripName(row[\"Requested domain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you stopped halfway, try will work. If you don't have a file that already exists, it will go to except\n",
    "try:\n",
    "    alreadyHave = pd.read_csv(\"WHOIS_missing_domains.csv\")\n",
    "\n",
    "    #find idx\n",
    "    lastSiteChecked = alreadyHave[\"Domain name\"].values[-1]\n",
    "    start_idx = list(scamsites[\"Domain name\"].values).index(lastSiteChecked)\n",
    "    df = alreadyHave\n",
    "    domainsToCheck = scamsites[\"Domain name\"].values[start_idx+1:]\n",
    "except:\n",
    "    df = pd.DataFrame()\n",
    "    domainsToCheck = scamsites[\"Domain name\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giqqhwgdq.bnkas.net/i1d9.html\n",
      "spp6c8jale-www.anewwayoffriday.com/#/login?code=wzojtf&tab=2\n",
      "d.krakenfly.xyz/?id=60079c26897537fd1b329c405c3a4e36\n",
      "down.959435.com/ijgq.html\n",
      "d.gdacvipa.buzz/?id=3437c2252ebe44294b698b4d397a3205\n",
      "d.app26526.xyz/?id=edc2c06fd20389553f3b2cd15cdaa178\n",
      "d.krakencla.com/?id=60079c26897537fd1b329c405c3a4e36\n",
      "www.elvannyou.com\n",
      "select-global.com\n",
      "wwwy.sdpyion.com\n",
      "engxin22.com\n",
      "d.app10581.xyz/?id=d16a1dd71954e8ed83ae8fb490905551\n",
      "d.gdacvipa.xyz/?id=3437c2252ebe44294b698b4d397a3205\n",
      "d.z2.wtf/6k1\n",
      "www.telebitex.com\n",
      "88678956.jsgj011.top:8967/index.php\n",
      "itestfilght.com/app/1577014610\n",
      "www.redeflag.com/bkopnw\n",
      "spp6me7kzzs-www.anewwayoffriday.com/#/login\n",
      "nl66sv1.cn\n",
      "www.huosuqian5555.top/jnbluw\n",
      "d.pfidcflu.buzz/?id=abe7ff16cf545fcf4c73853ca198709c\n",
      "www.charsin.com/app\n",
      "download.anyingouji.com\n",
      "forppea.penaker.com\n",
      "h5.myrtlesau.com\n",
      "m.wns.gh5685.cn\n",
      "www.duo-shou.cn/18500\n",
      "orpbj.ygxw18.website/9wm\n",
      "d.app91576.top/?id=d16a1dd71954e8ed83ae8fb490905551\n",
      "trw8wh2lcz-www.5gflare.com/#/login\n",
      "d.becexgbly.xyz/?id=754f821bce28644406a48430e4641cdf\n",
      "trade.ircatital-tw.com\n",
      "itestfilght.com/app/1578282458?lang=en\n",
      "m.aomahjs.com\n",
      "ww2.kjmxoxf.cn/1nex7.html\n",
      "d.lamresearchly.buzz/?id=ad03b5343953858505565eb49c3eafd5\n",
      "www.nbty35.com:30000\n",
      "www.323122.com:8930\n",
      "3018.shibo297.com:8003\n",
      "www.huanqiu147.com:20061\n",
      "www.183283.com:8930\n",
      "d.fexglobag.buzz/?id=686c6cd5115a5408290e6d484a52f637\n",
      "wap.yomanidctc.space\n",
      "d.app32103.top/?id=a08123dd8a75fc02fcabccbf15cb15e3\n",
      "empire-earnings.com\n"
     ]
    }
   ],
   "source": [
    "its = 0\n",
    "\n",
    "for name in domainsToCheck:\n",
    "    querystring[\"domain\"] = name\n",
    "    response = requests.request(\"GET\", url, params=querystring)\n",
    "    time.sleep(1)\n",
    "    response_dict = json.loads(response.text)\n",
    "    response_dict[\"Domain name\"] = name\n",
    "    \n",
    "    if \"error\" in response_dict:\n",
    "        print(name)\n",
    "        continue\n",
    "    \n",
    "    df = df.append(crawlJSON(response_dict), ignore_index=True)\n",
    "    \n",
    "    its += 1\n",
    "    \n",
    "    if its % 50 == 0:\n",
    "        df.to_csv(\"WHOIS_missing_domains.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final save\n",
    "df.to_csv(\"WHOIS_missing_domains.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
